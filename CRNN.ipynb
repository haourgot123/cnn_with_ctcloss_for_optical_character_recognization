{"cells":[{"cell_type":"code","execution_count":71,"metadata":{"executionInfo":{"elapsed":341,"status":"ok","timestamp":1726696788995,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"},"user_tz":-420},"id":"AOuGDCIed8Rk"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchsummary import summary"]},{"cell_type":"code","execution_count":72,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1726696789335,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"},"user_tz":-420},"id":"moMmVNiegGYP"},"outputs":[],"source":[" class CRNN(nn.Module):\n","  def __init__(self, char_list):\n","    super(CRNN, self).__init__()\n","\n","    self.conv_1 = nn.Conv2d(in_channels=1, out_channels=64,kernel_size=(3, 3), padding = 'same')\n","    self.pool_1 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n","    self.conv_2 = nn.Conv2d(in_channels=64, out_channels=128,kernel_size=(3, 3), padding = 'same')\n","    self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2)\n","    self.conv_3 = nn.Conv2d(in_channels=128, out_channels=256,kernel_size=(3, 3), padding = 'same')\n","    self.conv_4 = nn.Conv2d(in_channels=256, out_channels=256,kernel_size=(3, 3), padding = 'same')\n","    self.pool_4 = nn.MaxPool2d(kernel_size=(2, 1))\n","    self.conv_5 = nn.Conv2d(in_channels=256, out_channels=512,kernel_size=(3, 3), padding = 'same')\n","    self.norm_5 = nn.BatchNorm2d(512)\n","    self.conv_6 = nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(3, 3), padding = 'same')\n","    self.norm_6 = nn.BatchNorm2d(512)\n","    self.pool_6 = nn.MaxPool2d(kernel_size=(2,1))\n","    self.conv_7 = nn.Conv2d(in_channels=512, out_channels=512,kernel_size=(2, 2))\n","    self.bilstm_1 = nn.LSTM(\n","            input_size=512,\n","            hidden_size=128,\n","            num_layers=1,\n","            bidirectional=True,\n","            dropout=0.2,\n","            batch_first=True\n","        )\n","    self.bilstm_2 = nn.LSTM(\n","            input_size= 256,\n","            hidden_size=128,\n","            num_layers=1,\n","            bidirectional=True,\n","            dropout=0.2,\n","            batch_first=True\n","        )\n","    self.output = nn.Linear(in_features= 256, out_features= char_list + 1)\n","  def forward(self, x):\n","    x = self.conv_1(x)\n","    x = F.relu(x)\n","    x = self.pool_1(x)\n","    x = self.conv_2(x)\n","    x = F.relu(x)\n","    x = self.pool_2(x)\n","    x = self.conv_3(x)\n","    x = F.relu(x)\n","    x = self.conv_4(x)\n","    x = F.relu(x)\n","    x = self.pool_4(x)\n","    x = self.conv_5(x)\n","    x = F.relu(x)\n","    x = self.norm_5(x)\n","    x = self.conv_6(x)\n","    x = F.relu(x)\n","    x = self.norm_6(x)\n","    x = self.pool_6(x)\n","    x = self.conv_7(x)\n","    x = F.relu(x)\n","    x = x.squeeze()\n","    x = x.permute(0, 2, 1)\n","    x, _ = self.bilstm_1(x)\n","    x, _ = self.bilstm_2(x)\n","    x = self.output(x)\n","    x = F.softmax(x, dim = -1)\n","    return x\n","\n","\n"]},{"cell_type":"code","execution_count":73,"metadata":{"executionInfo":{"elapsed":381,"status":"ok","timestamp":1726696789711,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"},"user_tz":-420},"id":"o7VaCrDkKJ4V"},"outputs":[],"source":["# Encoder label\n","\n","def encoder_label(txt):\n","  dig_lst = []\n","  for index, char in enumerate(txt):\n","    try:\n","      dig_lst.append(char_list.index(char))\n","    except:\n","      print(char)\n","  return dig_lst"]},{"cell_type":"code","execution_count":74,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1726696789713,"user":{"displayName":"Hảo Nguyễn","userId":"10234462271197250553"},"user_tz":-420},"id":"KQtb5XzuAumR"},"outputs":[],"source":["batch_size = 64\n","max_label_len = 5\n","labels = torch.FloatTensor(batch_size, max_label_len)\n","input_len = torch.IntTensor(batch_size, 1)\n","label_len = torch.IntTensor(batch_size, 1)\n","ctc_loss = nn.CTCLoss(blank=62)"]},{"cell_type":"markdown","metadata":{"id":"Ui__w_0WBnP9"},"source":["# Unzip dataset\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"KhyemyArBl4J"},"outputs":[{"name":"stdout","output_type":"stream","text":["Archive:  /content/drive/MyDrive/CRNN/word.zip\n","replace dataset/word.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: "]}],"source":["!unzip /content/drive/MyDrive/CRNN/word.zip -d dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"-16ATQZjF1zF"},"outputs":[],"source":["# Xử lí file xml\n","import xml.etree.ElementTree as ET\n","import cv2\n","import os\n","import numpy as np\n","import string\n","\n","char_list = string.ascii_letters+string.digits\n","training_img = []\n","training_txt = []\n","train_input_length = []\n","train_label_length = []\n","orig_txt = []\n","\n","#lists for validation dataset\n","valid_img = []\n","valid_txt = []\n","valid_input_length = []\n","valid_label_length = []\n","valid_orig_txt = []\n","i = 1\n","max_label_len = 0\n","tree = ET.parse('dataset/word.xml')\n","root = tree.getroot()\n","print(f'Tên gốc: {root.tag}')\n","for child in root:\n","    file_name, word = child.attrib['file'], child.attrib['tag']\n","    print(file_name)\n","    img = cv2.cvtColor(cv2.imread(os.path.join('dataset', file_name)), cv2.COLOR_BGR2GRAY)\n","    # convert shape to (1, 32, 128)\n","    w, h = img.shape\n","    if h \u003e 128 or w \u003e 32:\n","      continue\n","    if w \u003c 32:\n","      add_zeros = np.ones((32 - w, h)) * 255\n","      img = np.concatenate((img, add_zeros))\n","    if h \u003c 128:\n","      add_zeros = np.ones((32, 128 - h)) * 255\n","      img = np.concatenate((img, add_zeros), axis = 1)\n","    img = np.expand_dims(img, 0)\n","    # normalize image\n","    img = img / 255\n","    if len(word) \u003e max_label_len:\n","      max_label_len = len(word)\n","    if i % 5 == 0:\n","      valid_orig_txt.append(word)\n","      valid_label_length.append(len(word))\n","      valid_input_length.append(31)\n","      valid_img.append(img)\n","      valid_txt.append(encoder_label(word))\n","    else:\n","      orig_txt.append(word)\n","      train_label_length.append(len(word))\n","      train_input_length.append(31)\n","      training_img.append(img)\n","      training_txt.append(encoder_label(word))\n","    i += 1\n","def pad_sequences(sequences, maxlen, padding_value):\n","    padded_sequences = []\n","\n","    for seq in sequences:\n","        seq_len = len(seq)\n","        if seq_len \u003c maxlen:\n","            # Thêm padding 'post'\n","            seq = seq + [padding_value] * (maxlen - seq_len)\n","        padded_sequences.append(seq)\n","\n","    return torch.tensor(padded_sequences)\n","\n","train_padded_txt = np.array(pad_sequences(training_txt, max_label_len, len(char_list)))\n","valid_padded_txt = np.array(pad_sequences(valid_txt, max_label_len, len(char_list)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L1gu63ifzoLn"},"outputs":[],"source":["training_img = np.array(training_img)\n","train_input_length = np.array(train_input_length)\n","train_label_length = np.array(train_label_length)\n","\n","valid_img = np.array(valid_img)\n","valid_input_length = np.array(valid_input_length)\n","valid_label_length = np.array(valid_label_length)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JJEwg7Fuib_l"},"outputs":[],"source":["# Sử dụng DataLoader\n","\n","from torch.utils.data import DataLoader\n","from torch.utils.data import Dataset\n","class Dataset(Dataset):\n","  def __init__(self, training_img, labels, training_label_length, train_input_length, transform = None):\n","    self.labels = labels\n","    self.training_img = training_img\n","    self.transform = transform\n","    self.label_lengths = training_label_length\n","    self.input_lengths = train_input_length\n","  def __len__(self):\n","    return len(self.training_img)\n","  def __getitem__(self, index):\n","    image = self.training_img[index]\n","    label = self.labels[index]\n","    label_length = self.label_lengths[index]\n","    input_length = self.input_lengths[index]\n","    return image, label, label_length, input_length\n","\n","# Tạo dataset\n","training_dataset = Dataset(training_img, train_padded_txt,train_label_length,train_input_length,  None)\n","valid_dataset = Dataset(valid_img, valid_padded_txt,valid_label_length, train_input_length, None)\n","# Tạo dataloader\n","train_loader = DataLoader(training_dataset, batch_size = 4,  shuffle=True, num_workers=1)\n","valid_loader = DataLoader(valid_dataset, batch_size = 4,  shuffle=True, num_workers=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwUWqaxhZHZ8"},"outputs":[],"source":["def validate(model, val_loader, criterion):\n","    model.eval()  # Đặt mô hình vào chế độ đánh giá (evaluation mode)\n","    val_loss = 0\n","    with torch.no_grad():  # Tắt gradient để tiết kiệm bộ nhớ và tăng tốc độ tính toán\n","        for images, labels, label_lengths, input_lengths in val_loader:\n","            images = images.float()\n","            outputs = model(images)  # [batch_size, seq_length, num_classes]\n","            outputs = outputs.log_softmax(2)  # Cần log_softmax để phù hợp với CTCLoss\n","            outputs = outputs.permute(1, 0, 2)\n","            # Tính toán loss cho tập validation\n","            loss = criterion(outputs, labels, input_lengths, label_lengths)\n","            val_loss += loss.item()\n","\n","    # Tính loss trung bình cho toàn bộ tập validation\n","    val_loss /= len(val_loader)\n","    return val_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"1u4JkUw5gc_6"},"outputs":[],"source":["import torch.optim as optim\n","\n","crnn = CRNN(len(char_list))\n","optimizer = optim.Adam(crnn.parameters(), lr = 0.0001)\n","ctc_loss = nn.CTCLoss()\n","num_epochs = 50\n","batch_size = 4\n","best_val_loss = float('inf')\n","for epoch in range(num_epochs):\n","  train_loss = 0\n","  crnn.train()\n","  for images, labels, label_lengths, input_lengths in train_loader:\n","    optimizer.zero_grad()\n","    images = images.float()\n","    outs = crnn(images)\n","    outs = outs.log_softmax(2).detach().requires_grad_()\n","    outs = outs.permute(1, 0, 2)\n","    loss = ctc_loss(outs, labels, input_lengths , label_lengths)\n","    loss.backward()\n","    optimizer.step()\n","    train_loss += loss.item()\n","\n","  train_loss /= len(train_loader)\n","  val_loss = validate(crnn, valid_loader, ctc_loss)\n","  print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n","  if val_loss \u003c best_val_loss:\n","        best_val_loss = val_loss\n","        torch.save(crnn.state_dict(), 'best_crnn_model.pth')\n","        print(f'Model saved with Validation Loss: {val_loss:.4f}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wgLTak4vCJv8"},"outputs":[],"source":["model_crnn = CRNN(len(char_list))\n","model_crnn.load_state_dict(torch.load(\"/content/best_crnn_model.pth\"))\n","model_crnn.eval()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"FTFHtZgZC7JI"},"outputs":[],"source":["with torch.no_grad():\n","  for images, labels, label_lengths, input_lengths in valid_loader:\n","    images = images.float()\n","    predictions = model_crnn(images)\n","\n","predictions.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUbS7iloEKYC"},"outputs":[],"source":["labels[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G93_DdUMGUw_"},"outputs":[],"source":["torch.argmax(predictions[0][3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zdbLzA_DFgTW"},"outputs":[],"source":["char_list[55]"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMacSs3JIowsBcN270MwlUZ","mount_file_id":"1cddMQP-kQtKbR7grpo02ktnCcH5iKgjU","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}